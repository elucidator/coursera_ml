---
title: "Practical Machine Learning Assignment"
author: "Pieter van der Meer"
date: "23-04-2015"
output: html_document
---

** Introduction **

This document is the "Prediction Assignment Writeup" for the coursera course "Practical Machine Learning". For background information on the assignment please refer to the course description.

** Data Description **
taken from [http://groupware.les.inf.puc-rio.br/har]
*** Weight Lifting Exercises Dataset *** 


**** On-body sensing schema **** 

This human activity recognition research has traditionally focused on discriminating between different activities, i.e. to predict "which" activity was performed at a specific point in time (like with the Daily Living Activities dataset above). The approach we propose for the Weight Lifting Exercises dataset is to investigate "how (well)" an activity was performed by the wearer. The "how (well)" investigation has only received little attention so far, even though it potentially provides useful information for a large variety of applications,such as sports training.

In this work (see the paper) we first define quality of execution and investigate three aspects that pertain to qualitative activity recognition: the problem of specifying correct execution, the automatic and robust detection of execution mistakes, and how to provide feedback on the quality of execution to the user. We tried out an on-body sensing approach (dataset here), but also an "ambient sensing approach" (by using Microsoft Kinect - dataset still unavailable)

Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).

Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes. Participants were supervised by an experienced weight lifter to make sure the execution complied to the manner they were supposed to simulate. The exercises were performed by six male participants aged between 20-28 years, with little weight lifting experience. We made sure that all participants could easily simulate the mistakes in a safe and controlled manner by using a relatively light dumbbell (1.25kg).

** Preparation of the dataset ***

```{r}
library(caret)
library(randomForest)
#Seems not to work on Ubuntu?
#library(doMC)

#Reproduciable results
set.seed(147852)

#Load the training data
trainingData = read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv");
```

*** Data set analysis ***
Initialy I tendend towards the data contained in the rows that have the new_window variable set to yes. Unfortunately the test data does not contain this value. This leads to all columns that are only filled when the latter are non-informative.

Next all near zero values are removed from the data set and the column number since that is non informative.

```{r}
#Remove all elements dat are not informative (i.e. averages and totals)
trainingData = trainingData[,-grep("^new_|^avg_|^user_name|^raw|^num|^total|^max|^min|^amplitude|^var|^stddev|^cvtd|^kurtosis|^skewness", colnames(trainingData))]

#Remove all near zero variables
trainingData = trainingData[,-nearZeroVar(trainingData[,-150])]

#Remove column index number
trainingData = trainingData[,-c(1)]
```

This leads to a dataset that contains only 48 (and the result or classe of the row) out of the original variables. 

** Splitting data set **
In order to create a training and test dataset it needs to be partitioned into training and test data. In this case I choose the standard 60/40 split.

```{r}
# Split into training and test data
inTrain = createDataPartition(y=trainingData$classe,p=0.6, list=FALSE)
training = trainingData[inTrain,]
testing = trainingData[-inTrain,]

rbind("original dataset" = dim(trainingData),"training set" = dim(training))
```

** Training the model **
Initially I went for a liniar model, but the predictions where not precise enough. The random forest was selected for training. The freebee you get with the forest that cross validation is implicit.

I experimented with the number of trees, a higher number of trees did not lead to a significant degreese in the error rate.

```{r}
#Running on a multicore
#doMC::registerDoMC(cores=4)
rf<-randomForest(classe ~ ., data=training, method="rf", prox=TRUE, ntree=300)
print(rf)
varImpPlot(rf)
```

** Running on the test data ** 
After model was trained The model is applied to the test data.

```{r}
predictions <- predict(rf, testing, type = "class")
confusionMatrix(predictions, testing$classe)
```

The model has an accuracy of 0.9961 and should be more then enough to predict the classe of the excercise.

** Getting the results **

The last step, running against the testing dataset is done with the model created.

```{r}
testDataUrl <- 'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv';
testData = read.csv(url(testDataUrl));

testDataPredictions = predict(rf, testData, type = "Class")

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_solutions/problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(testDataPredictions)
```

This places the results in the adviced format in a seperate directory.



** Notes on performance **
As can been seen in the code I experimented with running the code in parallel on my Ubuntu system. For some reasons not found by me the RF kept running on a single core.

I used both the doMC package and the parallel and doParallel packages. 

The doMC has no effect on performance.

Using the parallel and doParallel packages
Running:
```{r}
require(parallel)
require(doParallel)
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)

system.time(rf<-randomForest(classe ~ ., data=training, method="rf", prox=TRUE, ntree=300))
print(rf)
varImpPlot(rf)

stopCluster(cl)
```

Resulted in a run time of:
   user  system elapsed 
159.350   0.833 160.423 

Just on the single core (as is):
   user  system elapsed 
158.068   0.895 159.165 

Thus not a real game changer :-(